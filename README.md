# GSHO
## Grid search parameter optimization for models including RF, XGboost, LightGBM, SVR, and MLP.
1. This framework is adesigned for regression tasks. It supports traditional machine learning models including Random Forest, XGBoost, LGBM, and SVM, as well as the MLP neural network model. 
2. It features a fixed 10-fold cross-validation mechanism and hyperparameter optimization: traditional models use grid search, while the MLP uses randomized search.
3. Model evaluation is performed using multiple metrics including RÂ², RMSE, and MAE, ensuring both reproducibility and comprehensive assessment.
4. The framework follows a highly cohesive, low-coupling modular design and consists of six core files. config.py centrally manages all configurable items, including data file paths, cross-validation folds, random seeds, and other key parameters for easy adjustment. utils.py encapsulates reusable utility functions such as regression metric calculation and parameter grid size estimation. data_loader.py is dedicated to loading and basic preprocessing of Excel-formatted data, requiring the first six columns as features, the seventh column as the target variable, and all values to be numeric. models.py serves as the core training module, containing the definitions and training logic of all models. main.py acts as the program entry point, orchestrating the complete workflow from data loading, model training, to result saving. requirements.txt lists all dependencies including numpy, pandas, and scikit-learn for convenient environment setup.
5. To use the framework, first ensure Python 3.8 or above is installed, install dependencies via pip install -r requirements.txt, then modify configurations such as file paths in config.py to match the local environment. Finally, run python main.py to start training. During execution, the framework automatically performs model training and hyperparameter optimization. Upon completion, it prints the best model and key metrics in the console, exports a summary of evaluation results and optimal hyperparameters for all models to a specified Excel file, and saves the best MLP model as a .pkl file for later deployment and reuse.
6. Training efficiency can be adjusted by modifying the maximum iterations for MLP randomized search or the size of parameter grids. Common issues such as missing files or import errors can be resolved by checking path configurations and dependency installations. Poor model performance may be improved by verifying data quality or expanding the hyperparameter search space.
